express is minimal node framework a higher level of abstraction
it contains very robust features like complex routing easier handling of requests and responses 
express makes it easier to organise our application into MVC architecture which is very popular software architechture.

//APIS on  a higher level and rest architecture

API is a piece of software that can be used by other softwares to allow applications to talk to each other.

we can say node file system or http are small pieces of software we can interact with them by using their api 
for eg we use readFile of fs basically using the fs api 
thats why we say term node apis

for eg in java when we create classes and call methods these methods will be apis created from that class.

REST ARCHITECTURE

It is a way of building apis in a logical way making them easy to consume.
following procedure:

1)Seperate api into logical resources, these resources should then be exposed which means should be made available to structured,
resource based URLs to perform actions like reading,deleting etc

2) Use right http methods.

3) send data as json

4) must be stateless

Resource 

Object or representation of something which has data associated to it.any information that can be named can be a resource

we need to design url's to which data can be sent. API will have many endpoints that will perform actions.
so to gettours instead of gettours we can write tours 
it is advised to use resource name only in plural in the url.

for updating the object a put or patch request should be made.
in put entire object is sent
while in patch only changed object should be sent

any unique id should be a part of the url 

json is lightweight data interchange platform.

handling requests 

app.get('/', (req, res) => {// when a get method is called
    these req and res are slightly different from that in node they have more methods attached to them
   // res.status(200).send('Hello from the server side')
    we can also send json 
    res.status(200).json({ message: 'Hello from the server side', app: 'tour-and-travel' });
})
we do read file before not in the callback

***FOR POST REQUEST***

app.use(express.json);

this express.json here is a middleware.A middleware is a function taht can modify the incoming request data.It is called middleware because it stands in the middle of request and response.So,its just a step that a request goes through while its still in process.
The step that a request goes through is simply that data from the body is added to it.So its added to the req object.
we use app.use to use middleware.

app.post('/app/v1/tours', (req, res) => {
    console.log(req.body);
    res.send('done')
})

body is the property that is gonna be available on the request because we used that middleware 
we always need to send a response in order to complete the req-response cycle.

now after post req and after printing req.body which we get in the form of js object let's try adding our data to the json filr.
**MIDDLEWARE**
In the context of Node.js, middleware refers to functions or modules that have access to the request and response objects within the application's HTTP processing pipeline. Middleware functions in Node.js are executed in the order they are defined, and each middleware has the ability to modify the request or response, terminate the request-response cycle, or pass control to the next middleware in the stack.
expres.json
When you use this middleware in your Express application, it automatically parses the incoming request payload, assuming it is in JSON format, and attaches the parsed data to the request object under req.body.

here is how we will do it 
app.post('/api/v1/tours', (req, res) => {
    // console.log(req.body);
    const newId = tours[tours.length - 1].id + 1;
    const newTour = { ...req.body, id: newId }
    tours.push(newTour);
    fs.writeFile(`${__dirname}/dev-data/data/tours-simple.json`, JSON.stringify(tours), err => {
        res.status(201).json({
            status: 'success',
            data: {
                tour: newTour
            }
        })
    });
    //we can also do above by Object.assign({id:newId},req.body)
    // res.send('done');
})

we will obv use write file and not writeFileSync as we are in the event loop since all the callbacks will be executed in the event loop and we can never ever block the event loop.this is gonna happen in the background and as soon as it is ready it will be put in one of the event queues which is then gonna be handled as soon as the event loop passes that phase.


**RESPONDING TO URL PARAMETERS**
we will specify an id in url to get a specific tour

app.get('/api/v1/tours/:id', (req, res) => {
    console.log(req.params) // will tell the parameters in the url
    //here the value of key id would be in the form of string so we would hv to convert it
    //below code will convert it to a number
    const id = req.params.id * 1;
    const tour = tours.find(el => el.id === id)
    res.status(200).json({
        status: 'success',
        results: tours.length,
        data: {
            tours: tours
        }
    });
});

***PATCH REQUEST***

***DELETE REQUEST***

***REFACTORING OUR ROUTES***
routes should be kind of together and handling functions as well
as of now its difficult to see all routes together.
so let's put all the callbacks into their own functions.

after that we will get :->
app.get('/api/v1/tours', getAllTours);
app.get('/api/v1/tours/:id', getTour);
app.post('/api/v1/tours', createTour)
app.patch('/api/v1/tours/:id', updateTour)
app.delete('/api/v1/tours/:id', deleteTour)

while the entire code will be in these functions

now since lets say we want to update the version of route we can't do it again and again so 
app.get('/api/v1/tours', getAllTours);
this part can be written as 

app
    .route('/api/v1/tours')
    .get(getAllTours)
    .post(createTour)

app
    .route('/api/v1/tours/:id')
    .patch(updateTour)
    .delete(deleteTour)

    **THEORY REQUEST RESPONSE CYCLE**

    express app receives a request when someone hits the server for which it will create a request and response. 
    TO PRocess data we use middleware to manipulate any request or response object.
    we use express.json to get access to request body.
    it is a function executed between receiving a request and giving response.
    eg express.json
    
    All the middleware we use is called middleware stack.Order of the middleware stack is the way it is defined in the code.
    the middleware that appears first is executed earlier than the later ones.
    therefore order of code matters alot in express.

parsing,logging
    You can think like our req and response object will go each middleware in the middleware stack whre they are processed.
    or where just some other code is executed.Then at the end of each middleware function a next function is called the function taht we have access to in each middleware.
    when next is called the next middleware is executed.
    This whole process maybe like a pipeline.
    The last middleware is generally route handler.No next function called instead the response is sent back to the client.

    ***CREATING OUR OWN MIDDLEWARE***

    app.use -> we use this function to add to middleware stack
    express.json() returns a function that we want to add to middleware stack

    
app.use((req, res, next) => {
    console.log("Hello from the middleware")
    next();
})
next is used to call the next function in the middleware stack


middleware apply to every single request
to use middleware it should be put before the route handler

next we
const tourRouter = express.Router();
const userRouter = express.Router();

app.use('/api/v1/tours', tourRouter);
app.use('api/v1/users', userRouter);

router
    .route('/')
    .get(getAllUsers)
    .post(createUser)

router
    .route('/:id')
    .get(getUser)
    .patch(updateUser)
    .delete(deleteUser)

only put aage ka url in router.route() now

Install morgan middleware
check documentation of morgan to know more abt what it does

MOUNTING MULTIPLE ROUTERS

so we create userRoutes,tourRoutes and put all the code there
all the relevant code with their methods in seperate files and make sure to export those files
next, we need to import these modules 

next we create tourControllers and userController and put all the method definitions there
now we need to export method definitions 

since there are more than one methods instead of using module.exports we will replace all const of methods with exports

now while importing we write 
const tourController = require('./../controllers/tourController.js')
and while calling methods we write tourController.getAlltours

now we can also import in this way
const {getAlltours,getTour,.....} = require() actual names basically

next,we also create a server.js file
and server info in that file
we need to export app.js
now server.js will be the entry point

nodemon server.js

now in package.json
go here 
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1"
  },

and update this to

 "scripts": {
    "start": "nodemon server.js"
  },

now u just have to write npm start

for accessing the parameters in the url

router.param('id', (req, res, next, val) => {
    console.log(`Tour id is: ${val}`);
    next();
});

now we are checking id everytime which is a repeated code, to avoid repetition of code we can create a middleware 

exports.checkID = (req, res, next, val) => {
    console.log(`Tour id is: ${val}`);
    const id = req.params.id * 1;
    if (id > tours.length) {
        return res.status(404).json({
            status: 'fail',
            message: 'Invalid Id'
        });
    }
    next();
}

and now in tourRoutes 

router.param('id', tourController.checkID);

write like this

try to use more middlewares

Now similarly we can create a CheckBody middleware , check if body contains name and price property if not send 400 status code back

Let's now learn how to serve static files with Express.
Now what do I actually mean with static files?
Well, it's the files that are sitting in our file system
that we currently cannot access using all routes.
So, for example, we have this overview.html file here in our public folder.
But right now there's no way that we can access this using a browser, right?
And the same for these image files that we have here,or the CSS or the Javascript files.

So we can, of course, not just write public and then, for example,
overview.html, right?
There's no way we can access this right now.And that's simply because we didn't define any route
for this URL, right?We do not have any handler that is associated to this route.
And so, if we actually want to access something from our file system,we need to use a built-in Express middleware.

app.use(express.static(`${__dirname}/public`));
built-in express middleware

ENVIRONMENT VARIABLES

By default the env is set to devlopment,
you can check it using app.get('env)
console.log(process.env)
we can alsos et passwords and usernames using environment variables.It is not convenient to write env variables in the command we run to start application so we create config.env file where we define the env variables and we can also put sensitive information like username and password.
variable names should always be in upper-case

Now how do we connect this env to our backend?
we use package dotenv
so download and package and on the top of server.js (new entry point) we write 

in the same file write 
dotenv.config({ path: './config.env' })

check how to do in production in the last part of the video

MONGO-DB
In mongo, each database can have one or more collections(tables).Each collection can contain one or more documents,
(row in relational).

-->Mongo-db is a document database with scalability and flexibility that you want with the querying and indexing you need.

-->data stored in documents (field-value pair data structures)

-->very easy to distribute data among multiple machines as your users and amount of data grow.

-->no document data schema required so each document can have different number and type of fields.

-->Very performant due to features like embedded data models,indexing,sharding

-->MongoDB uses BSON data fromat for storing documents (similar to JSON but in BSON all values are typed that is all values have a data type)

In MongoDb we can have multiple values of a field,
we can embedd a document into other ,And this makes a database more performant in some situations because this way,
it can be easier to read all the data that we need all at once.
two more things about BSON documents.

First, the maximum size for each document is currently 16 MB, but this might increase in the future.
And second, each document contains a unique ID,which acts as a primary key of that document.
It's automatically generated with the object ID data type each time there is a new document,
and so we don't have to worry about it.

download compass
Creating remoted database hosted on MongoDB Atlas.

So Atlas is a so-called database as a service provider which takes all the pain of managing and scaling databases away from us.
So that already is a huge advantage for us but it's also extremely useful to always have our data
basically in the Cloud, because this way we can develop our application from everywhere
and, even more importantly, we don't have to export data from the local database and then upload it
to a hosted database, once we are ready to deploy our application.So instead we simply use this hosted database
right from the beginning, instead of even messing with local databases in the first place, all right?

create project using atlas

Connectng to our hosted database 
Now another thing that we can and should do,is to allow access from everywhere to this cluster.
So remember how right in the beginning of this video we whitelisted our IP in order to grant access
to our current computer to this cluster.
But if you happen to switch computers during development,you might need to whitelist the IP of that computer as well,
because otherwise you might not be able to connect.But since we're not really dealing with sensitive data here
anyway, we can simply whitelist every single IP in the world and allow access from everywhere.

go to network access and choose allow from everywhere after clicking edit

commands->

show dbs (showing all databases)
use db_name (for using database with name db_name)

Atlas atlas-wdpo49-shard-0 [primary] test> show dbs
tour-and-travel   40.00 KiB
admin            264.00 KiB
local             29.40 GiB
Atlas atlas-wdpo49-shard-0 [primary] test> use tour-and-travel
switched to db tour-and-travel
Atlas atlas-wdpo49-shard-0 [primary] tour-and-travel> db.tours.find()
[
  {
    _id: ObjectId('658d48fe093a30b262367e8a'),
    name: 'The Forest Hiker',
    price: 297,
    rating: 4.7
  }
]
the above document is the one we added

**Using MongoDb with Mongoose**

So, now it's finally time to connect the MongoDB database that we created with our Express application.
And, the first step in doing that is to actually get our connection string from Atlas.
So, just like we did before when we connected the database to Compass and to the Mongo Shell,
we need to get our connection string in order to connect the application to this hosted database.

Now among 3 options after clicking connect on cluster choose connect to application
now in the environment variables created create an env variable DATABASE=string

Next up, we need to install a MongoDB driver,so basically a software that allows our Node code
to access and interact with a MongoDB database.And, there are a couple of different MongoDB drivers,
but we're gonna use the one that I would say is the most popular one,which is called Mongoose, which adds a couple of features
to the more native MongoDB driver.

for connecting to database 

mongoose.connect(DB, {
    useNewUrlParser: true
    useCreateIndex: true,
    useFindAndModify: false
}).then((con) => {
    console.log(con.connections);
    console.log("DB connection successfully established")
}).catch((err) => {
    console.log(err);
});

now lets delete all existing collections,drop on atlas

What is mongoose?

Well, Mongoose is an object data modeling library for MongoDB and Node JS,
And by the way, an object data modeling library is just a way for us to write JavaScript code
that will then interact with a database.So, we could just use a regular MongoDB driver to access our database, and it would work just fine,but instead we use Mongoose,because it gives us a lot more functionality out of the box,
So, some of the features Mongoose give us is schemas to model our data and relationship,
easy data validation, a simple query API,middleware, and much more.In Mongoose, a schema is where we model our data,
so where we describe the structure of the data,default values, and validation.
We then take that schema and create a model out of it.And the model is basically a wrapper around the schema, which allows us to actually interface with the database in order to create, delete, update,and read documents.

Creating a simple tour model:->

model is a like a blueprint of documents.
so we need a mongoose model,for that we need schema.make a very simple schema for our tours.So, let's say tourSchema
is a new mongoose.Schema.
Add that in here we actually pass our schema as an object.

const tourSchema = new mongoose.Schema({
    name: {
        type: String,
        required: [true, 'A tour must have a name'],
        unique: true
    },
    rating: {
        type: Number,
        default: 4.5
    },
    price: {
        type: Number,
        required: [true, 'A tour must have a price']
    }

});

For example, this required here,this is actually something called a validator
because it is used to validate our data.
In this case, simply to validate if the name is actually there.(hence for data validation).

thats how we create a schema.now lets create model

const Tour = mongoose.model('Tour', tourSchema);

creating documents and testing the model
So, this is, again, a new documentthat we created out of a tour model,or function constructors,
and so as I said before, this is kinda using JavaScript function constructors.
const testTour= new Tour({
    name: "The Forest Hiker",
    rating: 4.7,
    price: 497
});

So we can now say testTour.save,and this will then save it to
he tours collection in the database, okay,and it's really as simple as that.
So again, we have our document instance which is testTour, and on there
we can then call the save method in order to save the document to the database.
Now this save here will then return a promise that we can then consume.

So for now, let's use then for that,and in the future, we will actually use
async await in order to consume these promises,but for now, let's keep it simple
and not create any more functions,and so instead, we're just using
the then method here.

**MVC ARCHITECTURE**

model,view,controller
model->business logic
view->presentation logic
controller->application logic

the model layer is concerned with everything about applications data,and the business logic.
And we're going to learn what business logic means in the next slide.Next up, we have the controller layer
and the function of the controllers is to handle the application's request,interact with models,and send back responses to the client.And all that is called the application logic.Finally, the view layer is necessary if we have a graphical interface in our app.Or in other words, if we're building a server-side rendered website,as we talked about before.In this case, the view layer consists basically of the templates used to generate the view,so the website that we're going to send back to the client.



So using a pattern, or an architecture like this allows us to write a more modular application,
which is going to be way easier to maintain in scale.

So as always, it all starts with a request.That request will hit one of our routers,Now the goal of the router is to delegate the request to the correct handler function,which will be in one of the controllers.

Then, depending on the incoming request,the controller might need to interact
with one of the models,for example to retrieve a certain document from the database,
or to create a new one.Once more, there is one model file for each resource.

In this case, after getting the data from the model,the controller will then select one of the view templates and inject the data into it.That rendered website will then be sent back
as the response.


So, one of the big goals of MVC is to separate business logic from application logic.So again, application logic
is the logic that makes the app actually work.For example, a big part of application logic in Express,
is all about managing requests and responses.So, in a sense, we can also say that application logic is more about technical stuff.
buss logic
it's all the code that actually solves the business problem
But we should do our best efforts to keep the application logic in our controllers and business logic in our models.

And there is even this philosophy of fat models, thin controllers,which says we should offload
as much logic as possible into the models,to keep the controllers as simple and lean as possible.

Refactoring for MVC
create models folder
copy the 
const tourSchema = new mongoose.Schema({
    name: {
        type: String,
        required: [true, 'A tour must have a name'],
        unique: true
    },
    rating: {
        type: Number,
        default: 4.5
    },
    price: {
        type: Number,
        required: [true, 'A tour must have a price']
    }

});

const Tour = mongoose.model('Tour', tourSchema);

to tourModel.js

remove below code as it was just for testing purposes

const testTour = new Tour({
    name: "The Park Camper",
    price: 997
});

testTour.save().then(doc => {
    console.log(doc);
}).catch(err => {
    console.log('ERROR  ', err);
});

now in tourController import the tour model
and remove the code 
 const tours = JSON.parse(fs.readFileSync(`${__dirname}/../dev-data/data/tours-simple.json`))
 no longer needed a file and all the tours code 

 remove this code 

 Another way of creating documents instead of prev way of  
 const testTour = new Tour({
    name: "The Park Camper",
    price: 997
});
we can call directly the create method on Tour in tourController
now instead of using then() on promises we will use async await make the method async and then you can await for result
tour.create will return the promise we await the promise

try creating tour , all those fields that are not a part of schema won't be added to the schema.however all the fields part of the schema should be present in the request body.

for get getAllTours
const tours = await Tour.find();
    res.status(200).json({
        status: 'success',
        results: tours.length,
        data: {
            tours
        }
    });

      await Tour.findById(req.params.id); id here because in the router we use :id so same name
      if not findById(req.params.id) we can also use findOne({_id:req.params.id})

for exporting 

exports.updateTour = async (req, res) => {

    try {
        const tour = await Tour.findByIdAndUpdate(req.params.id, req.body, {
            new: true,
            runValidators: true
        });
        res.status(200).json({
            status: 'success',
            data: {
                tour
            }
        })
    } catch (err) {
        res.status(400).json({
            status: 'fail',
            message: 'Invalid data sent'
        })
    }

}

fs.readFileSync('tours-simple.json', 'utf-8');
the above is json 
in import-dev-data.js
DB connection successfully established
PS C:\Users\SRISHTI\Desktop\Tour-and-Travel>
PS C:\Users\SRISHTI\Desktop\Tour-and-Travel> node "c:\Users\SRISHTI\Desktop\Tour-and-Travel\dev-data\data\import-dev-data.js" --delete
[
  'C:\\Program Files\\nodejs\\node.exe',
  'c:\\Users\\SRISHTI\\Desktop\\Tour-and-Travel\\dev-data\\data\\import-dev-data.js',
  '--delete'
]
DB connection successfully established
Data successfully deleted !!

#MAKING API BETTER

#FILTERNG

In mongoose 2 ways,
  const tours = await Tour.find({
            duration: 5,
            difficulty: 'easy'
        }); first way


        second way 

  const tours = await Tour.find().where('duration').equals(5).where(difficulty).equals('easy');

  we can have .lt() less than in advanced filtering 
  gte,gt,lte,lt

   //build query
        //filtering
        const queryObj = { ...req.query };
        const excludedFields = ['page', 'sort', 'limit', 'fields']
        excludedFields.forEach(el =>  delete queryObj[el] );
        console.log(req.query);

        // Advanced Filtering
        let queryStr = JSON.stringify(queryObj);
        queryStr = queryStr.replace(/\b(gte|gt|lt|lte)\b/g, match => `$${match}`);
        console.log(JSON.parse(queryStr));

        const query = Tour.find(JSON.parse(queryStr));
    query:127.0.0.1:3000/api/v1/tours?duration[gte]=5&difficulty=easy

//SORTING

for limiting 
127.0.0.1:3000/api/v1/tours?sort=price,ratingsAverage

for pagination

page=2&limit=10;
query=query.skip(10).limit(10) //skip 10 results



#REFACTORING APIS
#MONGODB AGGREGATION PIPELINE
And the idea is that we basically define a pipeline that all documents from a certain collection go through
where they are processed step by step in order to transform them into aggregated results.For example, we can use the aggregation pipeline in order to calculate averages or calculating minimum and maximum values or we can calculate distances even.

So this one is the match stage, all right?
And as I mentioned, it's really just a query.And so let's say that for starters,we only want to select documents
which have a ratings average greater or equal than 4.5.So can you do that?

And this group here is where the real magic happens because as the name says,
it allows us to group documents together,basically using accumulators.And an accumulator is for example,
even calculating an average.So if we have five tours, each of them has a rating,we can then calculate the average rating using group.

id is basically for every id you get different metrics grouped by them

#AGGREGATION PIPELINING:UNWINDING AND PIPELINING

basically we create monthly plan based on start dates.Because remember, we want to count how many tours there are for each of the months in a given year.
And what unwind is gonna do is basically deconstruct an array field from the info documents and then output one document for each element of the array.
so basically lets say a document had an array of startdates with 3 elements in it. So now 3 documents will be created with just unwind having startdates as each of those elements.

#VIRTUAL PROPERTIES:
All right, now virtual properties are basically fields that we can define on our schema but that will not be persisted.
So they will not be saved into the database.
Okay, so let's now define a virtual property that contains the tour duration in weeks.And so that's a field basically
that we can very easily convert from the duration that we already have in days, right?

Just like Express,Mongoose also has the concept of middleware.And so let's now learn about the first type of middleware, which is document middleware.
For example, each time a new document is saved to the database, we can run a function between the save command is issued and the actual saving of the document, or also after the actual saving.And that's the reason why Mongoose middleware is also called pre and post hooks.So again, because we can define functions to run before or after a certain event.

And in this lecture, we're gonna talk about document middleware, which is middleware that can act on the currently processed document.So just like the virtual properties,we define a middleware on the schema,so tourSchema.pre .And so this is for pre middleware, which again,is gonna run before an actual event.And that event in this case is the save event.
And so this call back function that we're gonna define here next,so function so this function will be called before an actual document is saved to the database.
So it runs before the save command and the .create command.But not on insert many.So if we use this command here, so insertMany,
then that will actually not trigger the save middleware.

So down here in our middleware function.And what I wanna do here is to create a slug for each of these documents.
So remember how in the first section,we created a slug for each of the products that we had in the store.
And so a slug is basically just a string that we can put in the URL, usually based on some string like the name.
So in this case, we're gonna create a slug based here on the tour name.So remember how for that we used the slugify package.
And so let's now go ahead and install that.

Now in this case, we only have one middleware function,which is why we didn't run into any problems,even not calling next, but let's actually now do that.And so each middleware function, in a pre save middleware has access to next.So that's exactly the same as in Express,and so by the end of the middleware we call next,and that will then call the next middleware in the stack.
So let's try this out again.And this is gonna be called test tour number two.Very simple, send to sky,and let's wait for it.
And now for some reason, it's not really here.Let's see if we got some error,and we actually did not.
But the reason why it's not working is that right now we don't have any slug in our schema.And remember this actually happened to us before when we only had a couple of fields in the schema.And when we, then we'll define some fields that were not in the schema, then they were simply not persisted to the database.And the same thing is now happening here,so we defined the slug property, but it's not in our schema.
And therefore it was then not saved to the database,and so let's quickly fix that and let's put it,
oh, I don't know, it doesn't really matter,
can put it here right after the name,so the slug should simply be a string.
And so that should fix it.

Let's now just very quickly experiment, also,with a post middleware.
So tourSchema.post and let's use save again.And then the callback function,which in the case of post middleware
has access not only to next, but also to the document that was just saved to the database.So let's call that one doc and then next.And so post middleware functions are executed after all the pre middleware functions have completed, all right.
So in here we actually no longer have the disk keyword,but instead we have the basically finished document here in doc.So let's just log that finished document to the console and then call next.Now in this case again, we only have one
post middleware and so we wouldn't really need next,but it's a best practice to simply always include it.
Now another thing that I wanted to show you is that we can have, of course, multiple pre middlewares or also post middlewares for the same hook.And hook is what we call this save here.So this middleware here is basically what we call
a pre save hook.

if we don't call next in the middleware function we will be stuck

this will point at the document

QUERY MIDDLEWARE

will be pointing at the query and not the document
let's say we can have secret tours only for vips and we don't want those turs to be shown in the result.
so we start by adding secretTour field in the schema

but for checking a particular tour by id 

tourSchema.post(/^find/, function(docs, next) {
  console.log(`Query took ${Date.now() - this.start} milliseconds!`);
  next();
});

we write regular expression for find so that all the strings starting with find the above middleware is applicable.
So find, as we just specified,and now, with our regular expression,it's also gonna run for find1,findOneAndDelete, findOneAndRemove.

we can also define any property so we define this.start
tourSchema.pre(/^find/, function(next) {
  this.find({ secretTour: { $ne: true } });

  this.start = Date.now();
  next();
});

So we learned about Document and query middleware, and now the last middleware that we're gonna talk about is aggregation middleware,and as you can probably guess,aggregation middleware allows us to add hooks before or after an aggregation happens,
and so let's now actually continue with our previous example where we did hide the secret tours from the queries, now in an aggregation the secret tours are still being used, right?So let's quickly confirm that actually,for example here in our gets tour stats,so that's where we used the first aggregation and so you see we have four tours here,four in easy, and three in medium
and so that makes 11 but we already know that we actually only want 10 tours.So there are 10 tours that are not secret,
and one that is secret, and so now we get all these 11 tours here and so basically we also want to exclude the secret tour in the aggregation.So how could we do that?Well let's take a look at where our aggregation is actually happening so it's down here in yeah,so in get tour steps, and so what we could do is to here in this match state simply exclude the secret tours
that are true right?So that would be quite easy to add here,but then we would have to add the same thing down here in the other aggregation that we have,and if we had even more aggregations we would then have to add that in all of them and that's of course
not a good idea, because for example we could forget.

this.pipeline() gives us the aggregation pipeline
this.pipeline() is array

We use unshift and so that is a standard JavaScript method for arrays okay, we have also shift to add at the end of the array and unshift at the beginning of the array, and so again what we want to add here now is to add just another stage, so very similar to what we have down here.So match and then secretTour, not equal to true.Give it a save, and so this piece of code here basically is exactly what we have up here right?Basically removing from the output all the documents that have secretTour set to true, right?

we can have as many match stages as we want

#DATA VALIDATION AND BUILT IN VALIDATORS

Now, what exactly does validation actually mean?Well, validation is basically checking if the entered
values are in the right format for each field in our document schema, and also that values
have actually been entered for all of the required fields.Now, on the other hand, we also have sanitization,
which is to ensure that the inputted data is basically clean, so that there is no malicious code
being injected into our database,or into the application itself.So, in that step we remove unwanted characters,
or even code, from the input data, all right?And this is actually a crucial step, like,a golden standard in back-end development.
To never, ever accept input data coming from a user as it is.So, we always need to sanitize that incoming data.

is because of the fat model and thin controller philosophy,we make changes in model.

 validate: {
        validator: function(val) {
          // this only points to current doc on NEW document creation
          return val < this.price;
        },
        message: 'Discount price ({VALUE}) should be below regular price'
      }

we can validate on our own

we have validator library as well

 name: {
      type: String,
      required: [true, 'A tour must have a name'],
      unique: true,
      trim: true,
      maxlength: [40, 'A tour name must have less or equal then 40 characters'],
      minlength: [10, 'A tour name must have more or equal then 10 characters']
      // validate: [validator.isAlpha, 'Tour name must only contain characters']
    },

    thats how we add

# ERROR HANDLING WITH EXPRESS
npm i ndb --global

scope->all variables

HANDLING UNHANDLES ROUTES
make a handler function for unhandled routes
go to app.js
here we add middleware after route handlers which will only execute incase not handled by above route handlers.
app.all('*', (req, res, next) => {
    res.status(404).json({
        status: 'fail',
        message: `Can't find ${req.originalUrl} on this server!`
    })
})

Operational errors
Problems we predict that will happen at some point so we just handle them in advance.invalid path accessed.

Programming errors
Bugs that we developers introduce into our code.Difficult to find and handle.eg using req.query instead of req.body

So, all we have to do is to write

a global express error handling middleware

which will then catch errors coming

from all over the application.

So, no matter if it's an error coming from a route handler,

or a model validator or really, someplace else,

the goal is that all these errors end up

in one central error handling middleware.

So that we can send a nice response back to the client

letting them know what happened.

And so, really, handling in this case just means

sending a response letting the user know what happened.

in app.js
app.use((err, req, res, next) => {
    
})
passing 4 parameters express automatically knows it is error middleware

Error is built in error class.

*******************************
Okay, and finally I actually also want

to export this middleware here, okay?

So basically, this handler

because throughout the rest of the section,

we're gonna build a couple of different

functions for handling with different types of errors,

and so I want all of these functions

to be all in the same file, all right?

And we can say that all of these functions

that I just mentioned are handlers, okay,

and so handlers, we also call them controllers

in the context of the MVC architecture,

and so let's now actually create

an error controller file in our controller folder.

Okay, and this might sound or look a bit weird

because we actually do not have an error resource

okay, and so probably some people are gonna disagree

with me that this is the correct place,

but I personally like to do it like this

because at the end of the day,

these functions, they kinda are like

really for controlling our errors, all right.
****************************************************************

 Catching Errors in Async Functions

 removing try catch blocks

 ///Adding 404 errors for id that is not found instead of returning NULL tour 
 next(..) next will call up the gloabal error middleware

 ****prod errors and dev errors**
 now prob is we are sending same errors in prod and dev but in prod we want to leak very little info abt errors to user.
 so
  if (process.env.NODE_ENV === 'development') {
        res.status(err.statusCode).json({
            status: err.status,
            error: err,
            message: err.message,
            stack: err.stack
        });
    } else if (process.env.NODE_ENV === 'production') {
        res.status(err.statusCode).json({
            error: err,
            message: err.message

        });
    }

now to make it cleaner seperate functions for dev and prod
we basically only want operational errors send to client in production and not programming erros etc

There are 3 types of errors created by mongoose we need to mark them operational to send meaningful error msgs back to the client.
invalid id 127.0.0.1:3000/api/v1/tours/awwwww like this 
posting tour ->duplicate key error (same tour already exists)
validation errors (like trying to update fields and failing validation errors)

so first is casterrors
   "stringValue": "\"awwwww\"",
        "valueType": "string",
        "kind": "ObjectId",
        "value": "awwwww",
        "path": "_id",
        "reason": {},
        "name": "CastError",
        "message": "Cast to ObjectId failed for value \"awwwww\" (type string) at path \"_id\" for model \"Tour\""
    },
    "message": "Cast to ObjectId failed for value \"awwwww\" (type string) at path \"_id\" for model \"Tour\"",
    "stack": "CastError: Cast to ObjectId failed for value \"awwwww\" (type string) at path \"_id\" for model \"Tour\"\n    at model.Query.exec (C:\\Users\\SRISHTI\\Desktop\\Tour-and-Travel\\node_modules\\mongoose\\lib\\query.js:4498:21)\n    at model.Query.Query.then (C:\\Users\\SRISHTI\\Desktop\\Tour-and-Travel\\node_modules\\mongoose\\lib\\query.js:4592:15)\n    at processTicksAndRejections (internal/process/task_queues.js:95:5)"

    this is the error we get

    we hv handled operationl asynchronous errors in global middleware
    unhandled errors->mongodb connection
    process.on('unhandledRejection', err => {
    console.log('UNHANDLED REJECTION! 💥 Shutting down...');
    console.log(err.name, err.message);
    //we first close the server and then callback function (server.close() we give time to server to handle pending requests before closing )
    server.close(() => {
        process.exit(1);
    });
});



Password Encryption:->
has to do with the data should be done in models only
we will use  mongoose pre save middleware which is a document middleware

//betweeen getting data and saving it we will manipulate/encrypt data
userSchema.pre('save', async function (next) {
    // Only run this function if password was actually modified(we only want to modify password if it is changed)
    if (!this.isModified('password')) return next();

    // Hash the password with cost of 12
    this.password = await bcrypt.hash(this.password, 12);

    // Delete passwordConfirm field
    this.passwordConfirm = undefined;
    next();
});

So this hash here is actually the asynchronous version,

but there also is a synchronous version.

But as you already know, we do not want to use

the synchronous version because

that will block the event loop and then prevent other users

from using the application.

So just like we learned in the beginning.

And so of course we want to use

the asynchronous version which is this one.

And this will then return a promise

and that promise, of course, we need to await.

And so, we need to use await and then say that this function

is an async function, just like this.

So, let's recap that here.

So, we want to set our current password

basically to encrypt this version of the original password

with a cost of 12, not to make it too easy

to break the password, but also not to make the application

take too long for encrypting the password, all right?

So with this, we encrypted our password

and now in the end, what we need to do

is to basically delete the confirm password, all right?

Because at this point in time,

we only have the real password hashed, right?

So, this dot password confirm,

So, this dot password confirm,

and how we basically delete the field,

so not to be persisted in the database

is to set it to undefined.

All right?

So, we really only need this password confirm here

for the validation that we implemented before.

So just to make sure that the user

actually inputted two equal passwords

so that he doesn't make any mistakes with his password.

How authentication with jwt works?

what does this mean?
So in simple terms, the whole work flow

of logging users in and allowing them

to interact with certain protected resources

that non-logged in users cannot access.

we will json web tokens, they re stateless solution for authentication we do not need to store session state
which is perfect for restful api taht we are building. because restful apis should always be stateless.

***ADDITIONAL TEXT***
RESTful APIs (Representational State Transfer) are designed to be stateless for several reasons, and adhering to statelessness is one of the key principles of REST architecture. Here are some reasons why RESTful APIs should be stateless:

Scalability: Stateless services are easier to scale horizontally because each request from a client contains all the information needed for the server to fulfill that request. There is no need for the server to store any session-related data between requests. This makes it easier to distribute the load across multiple servers without worrying about shared state.

Simplicity: Stateless architecture simplifies the design and implementation of APIs. Servers don't need to maintain information about the client's state between requests, reducing the complexity of the server logic.

Flexibility and Reliability: Stateless design allows for better flexibility and reliability. If a server fails or needs to be replaced, another server can seamlessly take over without relying on shared state information. Clients are not tied to a specific server, making the system more fault-tolerant.

Caching: Stateless nature makes it easier to implement caching mechanisms. Responses to requests can be easily cached since they do not depend on the client's state. This can improve the overall performance and reduce the load on the server.

Improved Security: Stateless APIs can be more secure because there is no persistent state information that could be exploited by attackers. Each request is treated in isolation, and security measures can be applied more consistently.

And the most widely used alternative to authentication with JWTs is to just store the user's log-in state
on the server using sessions.But then of course does not follow the principle that says that restful APIs should be stateless
and that's why we're opting for a solution like JWTs.

So now let's take a look at how authentication actually works with Json Web Tokens.
And assuming we already have a registered user
in our database, this is how a user logs into the app.
So the user's client starts by making a post request
with the username or email and the password.
The application then checks if the user exists
and if the password is correct.
And if so, a unique Json Web Token for only that user is created using a secret string
that is stored on a server.And a JWT itself is really just a string that looks something like this.

Anyway, the server then sends that JWT back to the client which will store it either in a cookie or in local storage.
And just like this the user is authenticated and basically logged into our application
without leaving any state on the server.So the server does in fact not know which users are actually logged in.
But of course, the user knows that he's logged in because he has a valid Json Web Token which is a bit like
a passport to access protected parts of the application.So again, just to make sure you got the idea.
A user is logged in as soon as he get back his unique valid Json Web Token which is not saved anywhere
on the server.And so this process is therefore completely stateless.Then, each time a user wants to access a protected route,
like his user profile data, for example,he sends his Json Web Token along with a request.
So it's a bit like showing his passport to get access to that route, right?
And that's probably the best and easiest way to understand this whole idea.
Now once the request hits the server, our app will then verify if the Json Web Token is actually valid.
So if the user is really who he says he is.And more about how this step works a bit later in this video.
Now if the token is actually valid, well,then the requested data will be sent to the client
and if not, then there will be an error telling the userthat he's not allowed to access that resource.
And as long as the user is logged in,this is how it's gonna work each time that he requests data
from any protected route.

SHORT EXPLANATION->

steps that occur during jwt authentication

Your explanation provides a clear and accurate overview of how JSON Web Tokens (JWTs) are used for stateless authentication in a RESTful API. Here's a summary of the key points:

User Authentication:

Upon successful authentication, the server generates a JWT containing user information.
This JWT is then sent back to the client.
Storage of JWT:

The client stores the JWT, either in a cookie or in local storage.
The JWT serves as a "passport" for the user, indicating that they are authenticated.
Server Statelessness:

The server does not store any information about the authenticated user, adhering to the statelessness principle of REST.
Accessing Protected Routes:

To access protected routes, the user includes the JWT in the request.
It's compared to showing a passport to gain access.
Token Verification:

Upon receiving the request, the server verifies the validity of the JWT.
If valid, the requested data is sent to the client.
If invalid, an error message is returned, indicating unauthorized access.
Stateless Process:

The entire process is stateless from the server's perspective.
Each request from the client contains the necessary authentication information.
Continuous User Authentication:

As long as the user presents a valid JWT, they can continue to access protected resources.

Now what's very important to note here is that all this communication must happen over https.
So secure encrypted http in order to prevent that anyone can get access to passwords or Json Web Tokens.
Only then we have a really secure system.


How does JWT VERIFICATION/AUTHENTICATION is done?

JWT Structure:

A JWT consists of three parts: Header, Payload, and Signature.
Header: Metadata about the token.
Payload: Data encoded into the token.
Signature: Created using the header, payload, and a secret key.
Token Encoding:

The header and payload are encoded but not encrypted, making them readable by anyone.
The size of the JWT depends on the amount of data encoded into the payload.
Signature and Token Signing:

The signature is created using the header, payload, and a secret key saved on the server.
This process is called signing the JWT.
The signature ensures the integrity and authenticity of the token.
Token Verification:

When a server receives a JWT for access to a protected route, it verifies the token.
Verification involves taking the header and payload and creating a test signature using the secret key.
The original signature, generated when the JWT was created, is still in the token.
If the test signature matches the original signature, it indicates that the payload and header have not been modified.
Security of JWT:

The secret key, known only to the server, is crucial for signing and verifying the JWT.
Without the secret, it is impossible to create a valid signature for new data.
Even if a third party manipulates the payload, they cannot create a matching signature without the secret.
Token Tampering Protection:

If the payload is manipulated, the original signature will not match the test signature during verification.
This ensures that any attempt to alter the payload will result in a failed verification.
Simplicity and Power of JWT:

The simplicity lies in the ability to verify the integrity of the data using a secret key.
The power comes from the security provided by the signature, making JWTs suitable for secure authentication and authorization.


Secret Key Generation:

The secret key used for signing and verifying JWTs is typically generated during the setup or initialization of the authentication system.
The key generation process might involve using a cryptographic library to create a strong and random secret key.
Storage:

Once generated, the secret key is stored securely. This often involves saving it as an environment variable, as mentioned earlier.
It is important to note that the secret key should never be hard-coded in the application code, as this could expose it in the source code repository.

A bit silly question. Isn't storing secret key in the server about the  JWT's secret key, makes it a stateful process instead of stateless ? 

No it doesn't make the process stateful, because in order to process a new request, the server never needs to remember anything about the previous request. All it does is to use a key stored in a variable, which has nothing to do with state.

**SIGNING UP USERS**

instead of create(req.body) we use const newUser = await User.create({
        name: req.body.name,
        email: req.body.email,
        password: req.body.password,
        passwordConfirm: req.body.passwordConfirm
    });
only take up details that we need otherwise anyone will send role as admin.
see documentation for jwt functions

Okay, so lets create our token here,

okay,

and I'll like to simply call it like this so just token,okay, then JWT dot sign, and now the first thing is the payload,
and this is basically an object for all the data
that we're going to store inside of the token,and in this case,
we really only want the ID of the user, all right, so nothing crazy here, not a lot of data
that's not really important.
define secretkey in config.env it should be 32 letters

all right, because using the standard HSA 256 encryption for the signature, the secret should at least be
thirty two characters long, all right,but the longer the better actually

So remember a environment variable is process dot end dot JWT secret,okay.
So at this point, we have the payload and we have the secret.The token header will actually created automatically
but now what we can also do is to pass on some options,
and the option that I'm gonna pass in
is when the JWT should expire.So this means that after the time that we're gonna pass in here,
the Jason web token is no longer gonna be valid,
even if it otherwise would be correctly verified,
all right,so this is basically for logging out a user after a certain period of time simply as a security measure,
 okay.
So let's actually define that expiration time also as a configuration variable here,

So we just created a token,now all we need to do,is to send it to the client.
So let's put it here before the user actually and then that's actually it.
That's really all we need to do to log in a new user,because right now we're not checking
if any password is correct or if the user actually exists in the database because here in this case,
the user was really just created,and so right away,we logged user into the application
by sending a token, okay,and the use of client should then in some ways store that token, just as we talked about before
in the previous lecture, okay,

and now what I want to show you,is the JWT debugger,
that I showed you as a screenshot earlier in the last video.
So let's go ahead and copy this token and then let's go to JWT.io,
okay,then down here we have the debugger and so let's delete this one here,and put ours and right away
you see that our signature is invalid,but that's because the sign function edits these two properties here,
because we specified an expiration date basically.So this here is issued at,and this is expiration time, okay,
so if we remove these two from here,you will see that now,this signature is actually verified,okay so what's important to notice here,is that of course the header is visible okay it's easily decodable basically,and so you that we did not specify any of this,it was the Json web token package that did it for us,but that here is actually the payload that we specified,
so if we take a look at this ID,it should be exactly the same as we have in postman,
so ending on six OF,and so indeed, it is exactly the same right,
okay, so these two here are open
and then the signature of course, we cannot really see,
because of course our secret is just that,it's really secret, all right,
so this was just to show you that everything works,and let's close this up,
and yeah, we're not able to log users in,but only if the user just signed up,
because in that case, we do not need to verifythe email in the database,
and also not the password, okay.

So doing all that is a way more complex process,
and so that's actually what we're gonna do
in the next lecture,
so next up, we will actually log in users,
based on their email address and their password.